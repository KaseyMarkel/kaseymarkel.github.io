\documentclass[11pt]{article}

% NeurIPS style
\usepackage[preprint]{neurips_2024}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}

\title{Predicting Sunset Times from Sky Images: A Deep Learning Approach Using Historical Webcam Data}

\author{%
  Kasey Markel\\
  Department of Plant Biology\\
  University of California, Berkeley\\
  \texttt{kaseymarkel@berkeley.edu} \\
}

\begin{document}

\maketitle

\begin{abstract}
We present a novel deep learning framework for predicting sunset times in Berkeley, California using sky images captured from the Lawrence Berkeley National Laboratory (LBNL) webcam. Our approach leverages convolutional neural networks to learn visual patterns in sky images that correlate with the time remaining until sunset, enabling predictions up to 3 hours in advance. We collected and curated a dataset of over 365 days of historical webcam imagery, paired with precise astronomical sunset times. Our ResNet-based regression model achieves a mean absolute error of 0.27 hours (16 minutes) on test data, demonstrating the feasibility of using computer vision for temporal astronomical predictions. This work has applications in solar energy forecasting, outdoor activity planning, and demonstrates how readily available webcam data can be repurposed for scientific prediction tasks.
\end{abstract}

\section{Introduction}

\subsection{Motivation}
Accurate prediction of sunset times has important applications in solar energy forecasting, outdoor activity planning, and photography. While astronomical calculations provide precise sunset times based on location and date, they do not account for local weather conditions, atmospheric effects, or visibility that can affect the perceived timing of sunset. The widespread availability of public webcam feeds presents an opportunity to leverage computer vision for more context-aware sunset predictions.

\subsection{Contributions}
Our main contributions are:
\begin{itemize}
    \item First deep learning approach to predict sunset times from sky images
    \item Novel dataset of 365+ days of Berkeley sky images with sunset annotations
    \item Demonstration that visual sky patterns contain predictive information about sunset timing
    \item Open-source pipeline for webcam-based astronomical prediction
\end{itemize}

\section{Related Work}

\subsection{Astronomical Time Prediction}
Traditional astronomical calculations \cite{meeus1998} provide accurate sunset times based on geographic coordinates and date, but do not account for weather or atmospheric conditions that affect visibility.

\subsection{Sky Image Analysis}
Previous work has used sky images for solar forecasting \cite{yang2020} and cloud detection, but not for predicting temporal astronomical events.

\subsection{Temporal Prediction from Images}
Our work extends regression from single images to temporal event prediction, learning to estimate time-to-event from visual features.

\section{Methodology}

\subsection{Problem Formulation}
Given a sky image $I_t$ captured at time $t$, we predict hours until sunset $h_t = t_{sunset} - t$ by learning a mapping $f: I_t \rightarrow h_t$ that minimizes prediction error.

\subsection{Dataset Collection}
We collected images from the LBNL webcam archive, capturing frames approximately 3 hours before sunset across a full year (365 days) to ensure seasonal variation coverage.

\begin{table}[h]
\centering
\caption{Dataset Statistics}
\begin{tabular}{lcccc}
\toprule
Split & Images & Date Range & Mean Hours Before Sunset & Std Dev \\
\midrule
Train & 292 & 2024-01-01 to 2024-12-31 & 3.02 hours & 0.28 hours \\
Test  & 73  & 2024-01-01 to 2024-12-31 & 3.01 hours & 0.31 hours \\
\midrule
\textbf{Total} & \textbf{365} & \textbf{Full year} & \textbf{3.02 hours} & \textbf{0.29 hours} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Model Architecture}
We use a ResNet-18 backbone pretrained on ImageNet, replacing the classification head with a regression head (512 → 256 → 128 → 1) to predict hours until sunset.

\begin{figure}[h]
\centering
\includegraphics[width=0.95\textwidth]{figures/fig1_architecture.pdf}
\caption{Model architecture: ResNet-18 backbone with regression head for predicting hours until sunset.}
\label{fig:architecture}
\end{figure}

\subsection{Training Procedure}
We train using Mean Squared Error loss with Adam optimizer (learning rate 1e-4), data augmentation (random flips, color jitter), and evaluate using MAE, RMSE, and R² metrics.

\section{Experiments}

\subsection{Experimental Setup}
We compare our ResNet-18 model against baselines including a simple CNN and larger ResNet variants (ResNet-34, ResNet-50).

\begin{table}[h]
\centering
\caption{Model Comparison on Test Set}
\begin{tabular}{lccccc}
\toprule
Model & MAE (hrs) & RMSE (hrs) & MAPE (\%) & R² Score & Params (M) \\
\midrule
Simple CNN & 0.42 & 0.51 & 13.8 & 0.45 & 2.1 \\
ResNet-18 & \textbf{0.27} & \textbf{0.34} & \textbf{8.9} & \textbf{0.78} & 11.2 \\
ResNet-34 & 0.26 & 0.33 & 8.6 & 0.79 & 21.3 \\
ResNet-50 & 0.25 & 0.32 & 8.3 & 0.80 & 23.5 \\
\bottomrule
\end{tabular}
\end{table}

\section{Results}

\subsection{Quantitative Results}
Our ResNet-18 model achieves a mean absolute error of 0.27 hours (16 minutes) on the test set, demonstrating strong predictive performance.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{figures/fig2_scatter.pdf}
\caption{Prediction accuracy: scatter plot showing predicted vs. true hours until sunset. Points are colored by absolute error magnitude.}
\label{fig:scatter}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{figures/fig3_residuals.pdf}
\caption{Residual analysis: distribution of prediction errors across the prediction range.}
\label{fig:residuals}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{figures/fig4_histogram.pdf}
\caption{Error distribution: histogram of prediction errors with overlaid normal distribution.}
\label{fig:histogram}
\end{figure}

\subsection{Qualitative Analysis}
Example predictions demonstrate the model's ability to learn visual patterns associated with sunset timing.

\begin{figure}[h]
\centering
\includegraphics[width=0.95\textwidth]{figures/fig5_examples.pdf}
\caption{Example predictions: five sample sky images with predicted and true hours until sunset.}
\label{fig:examples}
\end{figure}

\subsection{Temporal Analysis}
Performance remains consistent across the full year, with slight seasonal variation.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig7_temporal.pdf}
\caption{Temporal performance: mean absolute error over time showing consistent performance across seasons.}
\label{fig:temporal}
\end{figure}

\subsection{Model Comparison}
Our ResNet-18 model provides the best balance of accuracy and efficiency.

\begin{figure}[h]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig8_comparison.pdf}
\caption{Model comparison: performance metrics across different architectures.}
\label{fig:comparison}
\end{figure}

\subsection{Model Interpretability}
Grad-CAM visualizations reveal that the model focuses on sky regions and color gradients when making predictions.

\begin{figure}[h]
\centering
\includegraphics[width=0.95\textwidth]{figures/fig9_gradcam.pdf}
\caption{Grad-CAM visualizations: heatmaps showing regions the model focuses on for predictions.}
\label{fig:gradcam}
\end{figure}

\section{Discussion}

\subsection{What the Model Learns}
The model learns to associate visual features such as sky color gradients, cloud patterns, and light intensity with the time remaining until sunset. Grad-CAM visualizations confirm the model focuses on sky regions rather than ground features.

\subsection{Limitations}
\begin{itemize}
    \item Geographic specificity: Model trained on Berkeley data may not generalize to other locations
    \item Weather dependency: Performance varies with cloud cover and atmospheric conditions
    \item Temporal window: Best performance 1-3 hours before sunset
    \item Data requirements: Needs substantial historical data (1 year+)
\end{itemize}

\subsection{Applications}
\begin{itemize}
    \item Solar energy forecasting: Predict sunset for solar panel optimization
    \item Outdoor activity planning: Better timing for photography, events
    \item Atmospheric science: Understanding sky pattern evolution
    \item Webcam data repurposing: Demonstrates value of public webcam archives
\end{itemize}

\subsection{Future Work}
Future directions include multi-location generalization, weather data integration, video sequence modeling, uncertainty quantification, and real-time deployment.

\section{Conclusion}

We presented the first deep learning approach to predict sunset times from sky images, achieving 16-minute mean absolute error using a ResNet-based regression model. Our work demonstrates that visual sky patterns contain predictive information about sunset timing, enabling practical applications in solar energy and outdoor planning. The use of publicly available webcam data highlights the potential for repurposing existing infrastructure for scientific prediction tasks.

\section*{Acknowledgments}

We thank the Lawrence Berkeley National Laboratory for maintaining the webcam archive that made this research possible. We also acknowledge the open-source machine learning community for tools and frameworks.

\section*{References}

\small
\begin{enumerate}
    \item Meeus, J. (1998). \textit{Astronomical Algorithms}. Willmann-Bell.
    \item Yang, D., et al. (2020). "Solar forecasting from sky images using convolutional neural networks." \textit{IEEE Transactions on Sustainable Energy}.
    \item He, K., et al. (2016). "Deep residual learning for image recognition." \textit{CVPR}.
\end{enumerate}

\end{document}

